{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Masking, Reshape, Layer, Lambda, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as be\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updated Database pull to avoid duplicate columns, adding risk-free rate and converting risk free rate to yearly rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "# MySQL database connection function\n",
    "def connect_to_database():\n",
    "    try:\n",
    "        # Establishing connection to the database\n",
    "        connection = mysql.connector.connect(\n",
    "            host='crypto-matter.c5eq66ogk1mf.eu-central-1.rds.amazonaws.com',\n",
    "            database='Crypto',\n",
    "            user='Jing',  # Replace with your actual first name\n",
    "            password='Crypto12!'\n",
    "        )\n",
    "\n",
    "        if connection.is_connected():\n",
    "            db_info = connection.get_server_info()\n",
    "            print(\"Connected to MySQL database, MySQL Server version: \", db_info)\n",
    "            return connection\n",
    "\n",
    "    except Error as e:\n",
    "        print(\"Error while connecting to MySQL\", e)\n",
    "        return None\n",
    "\n",
    "# Function to query merged data from crypto_lending_borrowing and crypto_price tables\n",
    "def query_merged_crypto_data(connection):\n",
    "    query = \"\"\"\n",
    "    SELECT clb.lending_rate, clb.borrowing_rate, clb.utilization_rate, clb.stable_borrow_rate,\n",
    "    cp.*, usb.yield\n",
    "    FROM crypto_lending_borrowing clb\n",
    "    JOIN crypto_price cp \n",
    "        ON clb.crypto_symbol = cp.crypto_symbol\n",
    "        AND clb.date = cp.date\n",
    "    LEFT JOIN US_Bond_Yield usb\n",
    "        ON clb.date = usb.date\n",
    "    WHERE UPPER(clb.crypto_symbol) IN ('1INCHUSDT', 'BALUSDT', 'BATUSDT', 'CRVUSDT', 'ENJUSDT', 'ENSUSDT', 'KNCUSDT', 'LINKUSDT', 'MANAUSDT', 'MKRUSDT', 'RENUSDT', 'SNXUSDT', 'UNIUSDT', 'WBTCUSDT', 'YFIUSDT', 'ZRXUSDT')\n",
    "    \"\"\"\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    try:\n",
    "        # Execute the query\n",
    "        cursor.execute(query)\n",
    "\n",
    "        # Fetch all results\n",
    "        results = cursor.fetchall()\n",
    "\n",
    "        # Get column names from cursor description\n",
    "        columns = [desc[0] for desc in cursor.description]\n",
    "\n",
    "        # Convert results to a Pandas DataFrame\n",
    "        df = pd.DataFrame(results, columns=columns)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except Error as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "# Function to close the database connection\n",
    "def query_quit(connection):\n",
    "    if connection.is_connected():\n",
    "        connection.close()\n",
    "        print(\"MySQL connection is closed\")\n",
    "\n",
    "\n",
    "connection = connect_to_database()\n",
    "\n",
    "if connection:\n",
    "    # Query merged data\n",
    "    merged_df = query_merged_crypto_data(connection)\n",
    "    # converting US bond yield from hourly to yearly under continous compounding assumptions\n",
    "    merged_df['yield'] = np.exp(merged_df['yield']*365*24)-1\n",
    "\n",
    "    if merged_df is not None and not merged_df.empty:\n",
    "        # Display first few rows of the DataFrame\n",
    "        print(\"\\nMerged DataFrame:\")\n",
    "        print(merged_df.head())\n",
    "    else:\n",
    "        print(\"\\nNo data found after merging.\")\n",
    "\n",
    "    # Close the connection\n",
    "    query_quit(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block to get embeddings + pca for dim reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_llm_embeddings(dataframe, col, n_components=10):\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    unique_values = dataframe[col].unique()\n",
    "    \n",
    "    # Get embeddings for the unique values\n",
    "    embeddings = model.encode(unique_values, show_progress_bar=False)\n",
    "\n",
    "    # Apply PCA to reduce dimensionality\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    # Create a DataFrame to hold the reduced embeddings\n",
    "    reduced_embeddings_df = pd.DataFrame(reduced_embeddings, columns=[f'{col}_embedding_{i+1}' for i in range(n_components)])\n",
    "\n",
    "    reduced_embeddings_df[col] = unique_values\n",
    "\n",
    "    dataframe = dataframe.merge(reduced_embeddings_df, on=col, how='left')\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "merged_df_emb = create_llm_embeddings(merged_df, \"crypto_symbol\", n_components=15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code block for creating cyclical encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cyclical_encodings(df, date_col):\n",
    "    \n",
    "    days_in_month_dict = {\n",
    "    1: 31, 2: 28, 3: 31, 4: 30, 5: 31, 6: 30,\n",
    "    7: 31, 8: 31, 9: 30, 10: 31, 11: 30, 12: 31}\n",
    "\n",
    "    df[\"Year\"] = df[date_col].dt.year\n",
    "    df[\"Month\"] = df[date_col].dt.month\n",
    "    df[\"Day\"] = df[date_col].dt.day\n",
    "    df[\"Hour\"] = df[date_col].dt.hour\n",
    "    df[\"DayofWeek\"] = df[date_col].dt.dayofweek\n",
    "\n",
    "    # Vectorized leap year handling and days in month calculation\n",
    "    leap_year_mask = (df['Year'] % 4 == 0) & ((df['Year'] % 100 != 0) | (df['Year'] % 400 == 0))\n",
    "    df['days_in_month'] = df['Month'].map(days_in_month_dict)\n",
    "    \n",
    "    # Adjust February for leap years\n",
    "    df.loc[leap_year_mask & (df['Month'] == 2), 'days_in_month'] = 29\n",
    "\n",
    "    df[\"Month_Sine\"] = np.sin(2* np.pi * df[\"Month\"] / 12)\n",
    "    df[\"Month_Cosine\"] = np.cos(2* np.pi * df[\"Month\"] / 12)\n",
    "    \n",
    "    df[\"Day_Sine\"] = np.sin(2* np.pi * df[\"Day\"] / df['days_in_month'])\n",
    "    df[\"Day_Cosine\"] = np.cos(2* np.pi * df[\"Day\"] / df['days_in_month'])\n",
    "    \n",
    "    df[\"Hour_Sine\"] = np.sin(2* np.pi * df[\"Hour\"] / 24)\n",
    "    df[\"Hour_Cosine\"] = np.cos(2* np.pi * df[\"Hour\"] / 24)\n",
    "    \n",
    "    df[\"DayofWeek_Sine\"] = np.sin(2* np.pi * df[\"DayofWeek\"] / 7)\n",
    "    df[\"DayofWeek_Cosine\"] = np.cos(2* np.pi * df[\"DayofWeek\"] / 7)\n",
    "\n",
    "    df.drop(columns=[\"Month\", \"Day\", \"days_in_month\", \"Hour\", \"DayofWeek\", \"Year\"], inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "merged_df_emb = create_cyclical_encodings(merged_df_emb, \"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Architecture"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunable Parameters:\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_base_model(X_train, Y_class_train, X_valid, Y_class_valid,X_test,Y_class_test,\n",
    "                    cell_size=80, dropout_rate_1=0.3, dropout_rate_2=0.1, \n",
    "                    epochs=50,batch_size=30):\n",
    "    \n",
    "    be.clear_session()\n",
    "    \n",
    "    n_classes = 3\n",
    "\n",
    "    cell_size_1 = cell_size\n",
    "    cell_size_2 = cell_size_1//2\n",
    "    \n",
    "    inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    Masking_layer = Masking(mask_value=-50)(inputs)\n",
    "    Lstm_layer_1 = LSTM(cell_size_1, return_sequences=True, stateful=False, use_cudnn=False)(Masking_layer)\n",
    "    Batch_norm_1 = BatchNormalization()(Lstm_layer_1)\n",
    "    Dropout_layer_1 = Dropout(dropout_rate_1)(Batch_norm_1)\n",
    "    Lstm_layer_2 = LSTM(cell_size_2, return_sequences=False, stateful=False, use_cudnn=False)(Dropout_layer_1)  # just halved\n",
    "    Batch_norm_2 = BatchNormalization()(Lstm_layer_2)\n",
    "    Drouput_layer_2 = Dropout(dropout_rate_2)(Batch_norm_2)\n",
    "    predictions = Dense(Y_class_train.shape[1]*Y_class_train.shape[2]*n_classes, activation='softmax')(Drouput_layer_2)\n",
    "    predictions_reshaped = Reshape((Y_class_train.shape[1], Y_class_train.shape[2], n_classes),name=\"class\")(predictions)\n",
    "    LSTM_base = Model(inputs=inputs, outputs=predictions_reshaped)\n",
    "    \n",
    "    # we will keep this as a standardized learning rate optimizer across all models\n",
    "    optimizer = Adadelta(\n",
    "    learning_rate=1.0,\n",
    "    rho=0.8,\n",
    "    epsilon=1e-7)      # Default , to prevent division by zero)\n",
    "    \n",
    "    def sparse_crossentropy_masked(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        mask = tf.not_equal(y_true, -50)\n",
    "        y_true_masked = tf.boolean_mask(y_true, mask)\n",
    "        y_pred_masked = tf.boolean_mask(y_pred, mask)\n",
    "        loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(y_true_masked, y_pred_masked)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    LSTM_base.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=sparse_crossentropy_masked,\n",
    "        metrics=['accuracy'])\n",
    "    \n",
    "    LSTM_base.summary()\n",
    "    \n",
    "    history = LSTM_base.fit(x=X_train, y=Y_class_train,\n",
    "                    validation_data=(X_valid, Y_class_valid),\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    shuffle=False)\n",
    "    \n",
    "    # Extract the specific loss keys for class_predictions\n",
    "    class_train_loss_key = 'class_loss'\n",
    "    class_val_loss_key = 'val_class_loss'\n",
    "\n",
    "    # Plot the class_predictions losses\n",
    "    plt.plot(history.history[class_train_loss_key], label='Class Train Loss')\n",
    "    plt.plot(history.history[class_val_loss_key], label='Class Validation Loss')\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Losses Class Prediction')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred = LSTM_base.predict(X_test)\n",
    "\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "    def classification_metrics(y_true, y_pred):\n",
    "        valid_indices = y_true != -50\n",
    "        # Apply the mask to y_true and y_pred\n",
    "        y_true_filtered = y_true[valid_indices]\n",
    "        y_pred_filtered = y_pred[valid_indices]\n",
    "    \n",
    "        # Calculate the confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_true_filtered, y_pred_filtered)\n",
    "        \n",
    "        # Visualization of the confusion matrix using Seaborn\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_true_filtered, y_pred_filtered)\n",
    "        precision = precision_score(y_true_filtered, y_pred_filtered, average='macro', zero_division=0)\n",
    "        recall = recall_score(y_true_filtered, y_pred_filtered, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true_filtered, y_pred_filtered, average='macro', zero_division=0)\n",
    "        \n",
    "        # Printing classification metrics\n",
    "        print(\"Classification Metrics:\")\n",
    "        print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "        print(\"Precision: {:.2f}\".format(precision))\n",
    "        print(\"Recall: {:.2f}\".format(recall))\n",
    "        print(\"F1 Score: {:.2f}\".format(f1))\n",
    "    \n",
    "        # Detailed classification report\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(classification_report(y_true_filtered, y_pred_filtered, target_names=['0', '1', '2']))\n",
    "        return accuracy, precision, recall, f1\n",
    "    \n",
    "    accuracy, precision, recall, f1 = classification_metrics(Y_class_test,y_pred)\n",
    "    \n",
    "    return LSTM_base\n",
    "\n",
    "# Example usage\n",
    "LSTM_base = LSTM_base_model(X_train, Y_class_train, X_valid, Y_class_valid,X_test,Y_class_test,\n",
    "                    cell_size=80, dropout_rate_1=0.3, dropout_rate_2=0.1, \n",
    "                    epochs=20,batch_size=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Architecture"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra tunable hyperparamters:\n",
    "\n",
    "laten dim for VAE: The input is a divisor for cell size 2, cell size 2 is cell size 1 divided by 2, so maybe try 6,3,2. That would mean for cell size 124, latent dim would be in those 3 cases (4): 10,21,32. The other one is KL loss, I would suggest 0.01, 0.05, 0.1 and 0.2, and leave weight for entropy loss unchanged.\n",
    "\n",
    "Or for ease like this:\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_autoencoder_rates_and_class(X_train, Y_class_train, Y_train, X_valid, Y_class_valid,Y_valid,X_test, Y_class_test,\n",
    "                    cell_size=80, dropout_rate_1=0.3,latent_dim=6,\n",
    "                    epochs=50,batch_size=30, loss_weights=[1,0.1]):\n",
    "    \n",
    "    be.clear_session()\n",
    "    n_classes = 3\n",
    "\n",
    "    cell_size_1 = cell_size\n",
    "    cell_size_2 = cell_size_1//2\n",
    "    latent_dim = cell_size_2/latent_dim\n",
    "    \n",
    "    class KLDivergenceLayer(Layer):\n",
    "        def call(self, inputs):\n",
    "            z_mean, z_log_var = inputs\n",
    "            kl_loss = -0.5 * tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=-1)\n",
    "            self.add_loss(kl_loss)  # Add the KL loss to the layer's loss terms\n",
    "            return kl_loss\n",
    "        \n",
    "    inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    Masking_layer = Masking(mask_value=-50)(inputs)\n",
    "    Lstm_layer_1 = LSTM(cell_size_1,activation='tanh', return_sequences=True, stateful=False, use_cudnn=False)(Masking_layer)\n",
    "    Batch_norm_1 = BatchNormalization()(Lstm_layer_1)\n",
    "    Dropout_layer_1 = Dropout(dropout_rate_1)(Batch_norm_1)\n",
    "    Lstm_layer_2 = LSTM(cell_size_2,activation='tanh', return_sequences=False, stateful=False, use_cudnn=False)(Dropout_layer_1)  # just halved\n",
    "    Batch_norm_2 = BatchNormalization()(Lstm_layer_2)\n",
    "    \n",
    "    # Latent space representation (mean and log variance)\n",
    "    z_mean = Dense(latent_dim)(Batch_norm_2)\n",
    "    z_log_var = Dense(latent_dim)(Batch_norm_2)\n",
    "    \n",
    "    def sampling(args):\n",
    "        z_mean, z_log_var = args\n",
    "        epsilon = be.random_normal(shape=(be.shape(z_mean)[0], latent_dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "    z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_var])\n",
    "    \n",
    "    decoder_hidden = Dense(cell_size_2, activation='relu')(z)\n",
    "    reshaped_decoder_input = Reshape((1, cell_size_2))(decoder_hidden)\n",
    "    Lstm_decoder_1 = LSTM(cell_size_2, return_sequences=True, use_cudnn=False, activation='tanh')(reshaped_decoder_input)\n",
    "    Batch_norm_3 = BatchNormalization()(Lstm_decoder_1)\n",
    "    Lstm_decoder_2 = LSTM(cell_size_1, return_sequences=True, use_cudnn=False, activation='tanh')(Batch_norm_3)\n",
    "    Batch_norm_4 = BatchNormalization()(Lstm_decoder_2)\n",
    "    Dropout_layer_2 = Dropout(dropout_rate_1)(Batch_norm_4)\n",
    "    \n",
    "    class_predictions = Dense(Y_class_train.shape[1]*Y_class_train.shape[2]*n_classes, activation='softmax')(Dropout_layer_2)\n",
    "    class_predictions_reshaped = Reshape((Y_class_train.shape[1], Y_class_train.shape[2], n_classes),name=\"class\")(class_predictions)\n",
    "\n",
    "    kl_loss_layer = KLDivergenceLayer(name='kl_loss')([z_mean, z_log_var])\n",
    "\n",
    "    LSTM_base_decoder = Model(inputs=inputs,outputs=[class_predictions_reshaped, kl_loss_layer])\n",
    "    # we will keep this as a standardized learning rate optimizer across all models\n",
    "    optimizer = Adadelta(\n",
    "    learning_rate=1.0,\n",
    "    rho=0.8,\n",
    "    epsilon=1e-7)\n",
    "    \n",
    "    def sparse_crossentropy_masked(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.int32)\n",
    "        y_pred = tf.cast(y_pred, tf.float32)\n",
    "        mask = tf.not_equal(y_true, -50)\n",
    "        y_true_masked = tf.boolean_mask(y_true, mask)\n",
    "        y_pred_masked = tf.boolean_mask(y_pred, mask)\n",
    "        loss = tf.compat.v1.losses.sparse_softmax_cross_entropy(y_true_masked, y_pred_masked)\n",
    "        return tf.reduce_mean(loss)\n",
    "    \n",
    "    LSTM_base_decoder.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=[sparse_crossentropy_masked, lambda y_true, y_pred: tf.reduce_mean(y_pred)],\n",
    "        loss_weights = loss_weights)\n",
    "    \n",
    "    LSTM_base_decoder.summary()\n",
    "    \n",
    "    history = LSTM_base_decoder.fit(X_train, \n",
    "               [Y_class_train, np.zeros_like(Y_train)],\n",
    "               validation_data=(X_valid, [Y_class_valid, np.zeros_like(Y_valid)]),\n",
    "                                epochs=epochs,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=False)\n",
    "    \n",
    "    # Extract the specific loss keys for class_predictions\n",
    "    class_train_loss_key = 'class_loss'\n",
    "    class_val_loss_key = 'val_class_loss'\n",
    "\n",
    "    # Plot the class_predictions losses\n",
    "    plt.plot(history.history[class_train_loss_key], label='Class Train Loss')\n",
    "    plt.plot(history.history[class_val_loss_key], label='Class Validation Loss')\n",
    "\n",
    "    # Add labels and legend\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('Training and Validation Losses Class Prediction')\n",
    "    plt.show()\n",
    "\n",
    "    y_pred, y_placeholder = LSTM_base_decoder.predict(X_test)\n",
    "\n",
    "    y_pred = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "    def classification_metrics(y_true, y_pred):\n",
    "        valid_indices = y_true != -50\n",
    "        # Apply the mask to y_true and y_pred\n",
    "        y_true_filtered = y_true[valid_indices]\n",
    "        y_pred_filtered = y_pred[valid_indices]\n",
    "    \n",
    "        # Calculate the confusion matrix\n",
    "        conf_matrix = confusion_matrix(y_true_filtered, y_pred_filtered)\n",
    "        \n",
    "        # Visualization of the confusion matrix using Seaborn\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['0', '1', '2'], yticklabels=['0', '1', '2'])\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_true_filtered, y_pred_filtered)\n",
    "        precision = precision_score(y_true_filtered, y_pred_filtered, average='macro', zero_division=0)\n",
    "        recall = recall_score(y_true_filtered, y_pred_filtered, average='macro', zero_division=0)\n",
    "        f1 = f1_score(y_true_filtered, y_pred_filtered, average='macro', zero_division=0)\n",
    "        \n",
    "        # Printing classification metrics\n",
    "        print(\"Classification Metrics:\")\n",
    "        print(\"Accuracy: {:.2f}\".format(accuracy))\n",
    "        print(\"Precision: {:.2f}\".format(precision))\n",
    "        print(\"Recall: {:.2f}\".format(recall))\n",
    "        print(\"F1 Score: {:.2f}\".format(f1))\n",
    "    \n",
    "        # Detailed classification report\n",
    "        print(\"\\nDetailed Classification Report:\")\n",
    "        print(classification_report(y_true_filtered, y_pred_filtered, target_names=['0', '1', '2']))\n",
    "        return accuracy, precision, recall, f1\n",
    "    \n",
    "    accuracy, precision, recall, f1 = classification_metrics(Y_class_test,y_pred)\n",
    "    \n",
    "    return LSTM_base_decoder\n",
    "\n",
    "LSTM_base_decoder = LSTM_autoencoder_rates_and_class(X_train, Y_class_train, X_valid, Y_class_valid,Y_valid,X_test, Y_class_test,\n",
    "                    cell_size=80, dropout_rate_1=0.3,latent_dim=10,l2_strength=0.1,\n",
    "                    epochs=20,batch_size=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
