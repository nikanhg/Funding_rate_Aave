{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed hourly market cap data for 1inchusdt.txt .\n",
      "Processed hourly market cap data for balusdt.txt .\n",
      "Processed hourly market cap data for batusdt.txt .\n",
      "Processed hourly market cap data for crvusdt.txt .\n",
      "Processed hourly market cap data for enjusdt.txt .\n",
      "Processed hourly market cap data for ensusdt.txt .\n",
      "Processed hourly market cap data for kncusdt.txt .\n",
      "Processed hourly market cap data for linkusdt.txt .\n",
      "Processed hourly market cap data for manausdt.txt .\n",
      "Processed hourly market cap data for mkrusdt.txt .\n",
      "Processed hourly market cap data for renusdt.txt .\n",
      "Processed hourly market cap data for snxusdt.txt .\n",
      "Processed hourly market cap data for uniusdt.txt .\n",
      "Processed hourly market cap data for wbtcusdt.txt .\n",
      "Processed hourly market cap data for yfiusdt.txt .\n",
      "Processed hourly market cap data for zrxusdt.txt .\n"
     ]
    }
   ],
   "source": [
    "# Directory containing all token data files\n",
    "data_dir = 'market caps'\n",
    "\n",
    "# Initialize an empty list to store data from all tokens\n",
    "all_tokens_data = []\n",
    "\n",
    "# Process each file in the directory\n",
    "for file_name in os.listdir(data_dir):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_path = os.path.join(data_dir, file_name)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        # Extract the token name and series data\n",
    "        token_name = file_name\n",
    "        data_points = data['data']['series'][0]['points']\n",
    "\n",
    "        # Convert the data into a DataFrame\n",
    "        data_df = pd.DataFrame(data_points, columns=['timestamp', 'market_cap'])\n",
    "        data_df['token'] = token_name\n",
    "\n",
    "        # Step 1: Get market caps and timestamps into a DataFrame (already done above)\n",
    "\n",
    "        # Step 2: Remove rows with zeros and NAs\n",
    "        data_df = data_df[(data_df['market_cap'] != 0) & (~data_df['market_cap'].isna())]\n",
    "\n",
    "        # Step 3: Populate hourly data\n",
    "        data_df['timestamp'] = pd.to_datetime(data_df['timestamp'], unit='s')\n",
    "        final_data = []\n",
    "        for i in range(len(data_df) - 1):\n",
    "            current_row = data_df.iloc[i]\n",
    "            next_row = data_df.iloc[i + 1]\n",
    "\n",
    "            current_time = current_row['timestamp']\n",
    "            next_time = next_row['timestamp']\n",
    "            market_cap = next_row['market_cap']  # Use next week's market cap\n",
    "\n",
    "            # Generate hourly timestamps between current_time and next_time\n",
    "            while current_time < next_time:\n",
    "                final_data.append({'timestamp': current_time, 'market_cap': market_cap, 'token': current_row['token']})\n",
    "                current_time += timedelta(hours=1)\n",
    "\n",
    "        # Add the last timestamp of the last data point\n",
    "        final_data.append({'timestamp': data_df.iloc[-1]['timestamp'], 'market_cap': data_df.iloc[-1]['market_cap'], 'token': data_df.iloc[-1]['token']})\n",
    "\n",
    "        # Convert to DataFrame\n",
    "        hourly_df = pd.DataFrame(final_data)\n",
    "\n",
    "        # Append to all tokens data\n",
    "        all_tokens_data.append(hourly_df)\n",
    "\n",
    "        print(f\"Processed hourly market cap data for {token_name} .\")\n",
    "\n",
    "# Combine all tokens data into a single DataFrame\n",
    "combined_df = pd.concat(all_tokens_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_clean(name):\n",
    "     name = name.replace('.txt', '')\n",
    "     name = name.upper()\n",
    "     return name\n",
    "\n",
    "combined_df['token'] = combined_df['token'].apply(token_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1INCHUSDT\n",
      "34777\n",
      "2020-12-21 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "BALUSDT\n",
      "39145\n",
      "2020-06-22 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "BATUSDT\n",
      "43681\n",
      "2019-12-16 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "CRVUSDT\n",
      "37969\n",
      "2020-08-10 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "ENJUSDT\n",
      "43681\n",
      "2019-12-16 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "ENSUSDT\n",
      "27049\n",
      "2021-11-08 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "KNCUSDT\n",
      "29569\n",
      "2021-07-26 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "LINKUSDT\n",
      "43681\n",
      "2019-12-16 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "MANAUSDT\n",
      "43681\n",
      "2019-12-16 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "MKRUSDT\n",
      "43681\n",
      "2019-12-16 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "RENUSDT\n",
      "43681\n",
      "2019-12-16 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "SNXUSDT\n",
      "43681\n",
      "2019-12-16 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "UNIUSDT\n",
      "37129\n",
      "2020-09-14 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "WBTCUSDT\n",
      "37465\n",
      "2020-08-31 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "YFIUSDT\n",
      "38641\n",
      "2020-07-13 00:00:00\n",
      "2024-12-09 00:00:00\n",
      "ZRXUSDT\n",
      "43681\n",
      "2019-12-16 00:00:00\n",
      "2024-12-09 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# ens, knc, uni, yfi\n",
    "for t in combined_df['token'].unique():\n",
    "     print(t)\n",
    "     print(len(combined_df[combined_df['token'] == t]))\n",
    "     print(min(combined_df[combined_df['token'] == t]['timestamp']))\n",
    "     print(max(combined_df[combined_df['token'] == t]['timestamp']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>market_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>631192</td>\n",
       "      <td>6.311920e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2022-08-26 00:07:36.439244544</td>\n",
       "      <td>1.750222e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2019-12-16 00:00:00</td>\n",
       "      <td>2.329329e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021-07-17 15:00:00</td>\n",
       "      <td>2.570785e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2022-09-09 04:00:00</td>\n",
       "      <td>5.273453e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2023-10-25 02:00:00</td>\n",
       "      <td>1.422480e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-12-09 00:00:00</td>\n",
       "      <td>2.215067e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.954620e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           timestamp    market_cap\n",
       "count                         631192  6.311920e+05\n",
       "mean   2022-08-26 00:07:36.439244544  1.750222e+09\n",
       "min              2019-12-16 00:00:00  2.329329e+07\n",
       "25%              2021-07-17 15:00:00  2.570785e+08\n",
       "50%              2022-09-09 04:00:00  5.273453e+08\n",
       "75%              2023-10-25 02:00:00  1.422480e+09\n",
       "max              2024-12-09 00:00:00  2.215067e+10\n",
       "std                              NaN  2.954620e+09"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('market_cap_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of Notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
